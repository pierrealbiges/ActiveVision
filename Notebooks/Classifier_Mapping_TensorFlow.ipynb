{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_reshape_128(x, i_offset = 0, j_offset = 0):\n",
    "    assert x.shape == (28 * 28,)\n",
    "    image = x.reshape(28, 28)\n",
    "    image = np.append(np.zeros((128 + 2, 28)), image, axis = 0)\n",
    "    image = np.append(image, np.zeros((128 + 2, 28)), axis = 0)\n",
    "    image = np.append(np.zeros((288, 128 + 2)), image, axis = 1)\n",
    "    image = np.append(image, np.zeros((288, 128 + 2)), axis = 1)\n",
    "    return image[128 + 16 - 64 - i_offset : 128 + 16 + 64 - i_offset, 128 + 16 - 64 - j_offset : 128 + 16 + 64 - j_offset]\n",
    "\n",
    "def minmax(value,   #valeur a delimiter\n",
    "           border): #limite min/max a ne pas depasser \n",
    "    value = max(value, -border)\n",
    "    value = min(value, border)\n",
    "    return value\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def softmax_label_to_value(softmax_label):\n",
    "    y_num = 0\n",
    "    for n in softmax_label:\n",
    "        if n == np.max(softmax_label): \n",
    "            value = y_num\n",
    "            break\n",
    "        y_num += 1\n",
    "    return value  \n",
    "\n",
    "def one_hot_label_to_value(one_hot_label):\n",
    "    y_num = 0\n",
    "    for n in one_hot_label:\n",
    "        if n == 1: \n",
    "            value = y_num\n",
    "            break\n",
    "        y_num += 1\n",
    "    return value  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fecd8260860>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npIKhIKlgKEgq/D+T0Yc6CMwTrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fecd82b8c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_image_sample = mnist_reshape_128(mnist.train.images[5], 10,10)\n",
    "plt.imshow(mnist_image_sample, cmap= 'gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1500\n",
    "iterations = 400\n",
    "alpha = 0.1\n",
    "vector_size = 128*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.random_normal([vector_size,10], stddev=0.1), name='weights')\n",
    "x_train = tf.placeholder(tf.float32, shape=[None,vector_size], name='t_train')\n",
    "labels = tf.placeholder(tf.float32, shape=[None,10], name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo = tf.nn.softmax(tf.matmul(x_train, weights))\n",
    "cost = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=hypo)\n",
    "optimizer = tf.train.AdamOptimizer(alpha).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n"
     ]
    }
   ],
   "source": [
    "for it in range(iterations):\n",
    "    batch = mnist.test.next_batch(batch_size)\n",
    "    x_list, label_list = [],[]\n",
    "    count_example = 0\n",
    "    for example in batch[0]:\n",
    "        i_off, j_off = minmax(int(np.random.randn() * 15),100), minmax(int(np.random.randn() * 15),100)\n",
    "        image = mnist_reshape_128(example, i_off, j_off)\n",
    "        x_list += [np.ravel(image)]\n",
    "        label_list += [batch[1][count_example]]\n",
    "        count_example += 1\n",
    "        \n",
    "    sess.run(optimizer, {x_train: x_list, labels: label_list})\n",
    "    \n",
    "    if it%20==0: print(it,'/',iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_batch_size = 1000\n",
    "iterations = 100\n",
    "vector_size = 128*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_values = weights.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "20.61\n"
     ]
    }
   ],
   "source": [
    "correct_numb = 0\n",
    "for it in range(iterations):\n",
    "    eval_batch = mnist.test.next_batch(eval_batch_size)\n",
    "    example_numb = 0\n",
    "    for example in eval_batch[0]:\n",
    "        i_off, j_off = minmax(int(np.random.randn() * 15),100), minmax(int(np.random.randn() * 15),100)\n",
    "        image = mnist_reshape_128(example, i_off, j_off)\n",
    "        cat_off = eval_batch[1][example_numb]\n",
    "        cat_hat = softmax(np.dot(np.ravel(image), weights_values))\n",
    "        if one_hot_label_to_value(cat_off) == softmax_label_to_value(cat_hat):\n",
    "            correct_numb += 1\n",
    "        example_numb += 1\n",
    "    if it%10 == 0: print(it)\n",
    "percent_correct = (correct_numb*100)/(iterations*eval_batch_size)\n",
    "print(percent_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
