{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T15:09:04.278565Z",
     "start_time": "2018-05-31T15:09:04.251222Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T15:09:22.052835Z",
     "start_time": "2018-05-31T15:09:04.284852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading accuracy... min, max= 0.0145 0.9852\n"
     ]
    }
   ],
   "source": [
    "from Where import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T00:03:21.648596Z",
     "start_time": "2018-05-31T15:09:22.061639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model... with lr= 0.005\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6940068602561951 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.69020676612854 Time: 1.64 mn\n",
      "[20000/60000] Loss: 0.686435341835022 Time: 3.27 mn\n",
      "[30000/60000] Loss: 0.6821590065956116 Time: 4.89 mn\n",
      "[40000/60000] Loss: 0.6771063804626465 Time: 6.52 mn\n",
      "[50000/60000] Loss: 0.6714149713516235 Time: 8.05 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6642682552337646 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.6555736660957336 Time: 1.55 mn\n",
      "[20000/60000] Loss: 0.6440843343734741 Time: 3.08 mn\n",
      "[30000/60000] Loss: 0.6300716996192932 Time: 4.60 mn\n",
      "[40000/60000] Loss: 0.6116200685501099 Time: 6.11 mn\n",
      "[50000/60000] Loss: 0.5878795981407166 Time: 7.63 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.5591170191764832 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.5251481533050537 Time: 1.53 mn\n",
      "[20000/60000] Loss: 0.49044787883758545 Time: 3.05 mn\n",
      "[30000/60000] Loss: 0.455188512802124 Time: 4.57 mn\n",
      "[40000/60000] Loss: 0.42905309796333313 Time: 6.08 mn\n",
      "[50000/60000] Loss: 0.4036509394645691 Time: 7.60 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.39307984709739685 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.38745012879371643 Time: 1.52 mn\n",
      "[20000/60000] Loss: 0.37625110149383545 Time: 3.04 mn\n",
      "[30000/60000] Loss: 0.3751339912414551 Time: 4.55 mn\n",
      "[40000/60000] Loss: 0.3771582245826721 Time: 6.06 mn\n",
      "[50000/60000] Loss: 0.3774304986000061 Time: 7.56 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37880340218544006 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.37487491965293884 Time: 1.52 mn\n",
      "[20000/60000] Loss: 0.3729809522628784 Time: 3.05 mn\n",
      "[30000/60000] Loss: 0.3770211338996887 Time: 4.57 mn\n",
      "[40000/60000] Loss: 0.3733068108558655 Time: 6.08 mn\n",
      "[50000/60000] Loss: 0.37425610423088074 Time: 7.60 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37038129568099976 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3703422546386719 Time: 1.53 mn\n",
      "[20000/60000] Loss: 0.37528571486473083 Time: 3.04 mn\n",
      "[30000/60000] Loss: 0.3760764002799988 Time: 4.55 mn\n",
      "[40000/60000] Loss: 0.37159037590026855 Time: 6.07 mn\n",
      "[50000/60000] Loss: 0.3751034438610077 Time: 7.57 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37915679812431335 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3784300982952118 Time: 1.54 mn\n",
      "[20000/60000] Loss: 0.36922863125801086 Time: 3.04 mn\n",
      "[30000/60000] Loss: 0.373277872800827 Time: 4.56 mn\n",
      "[40000/60000] Loss: 0.3700827360153198 Time: 6.08 mn\n",
      "[50000/60000] Loss: 0.37113747000694275 Time: 7.59 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37449151277542114 Time: 0.02 mn\n",
      "[10000/60000] Loss: 0.3738720417022705 Time: 1.54 mn\n",
      "[20000/60000] Loss: 0.3751369118690491 Time: 3.05 mn\n",
      "[30000/60000] Loss: 0.3762950897216797 Time: 4.54 mn\n",
      "[40000/60000] Loss: 0.37016984820365906 Time: 5.97 mn\n",
      "[50000/60000] Loss: 0.3695113956928253 Time: 7.40 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3689177930355072 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.37205010652542114 Time: 1.44 mn\n",
      "[20000/60000] Loss: 0.36754339933395386 Time: 2.87 mn\n",
      "[30000/60000] Loss: 0.3721938133239746 Time: 4.30 mn\n",
      "[40000/60000] Loss: 0.3742533028125763 Time: 5.72 mn\n",
      "[50000/60000] Loss: 0.37613484263420105 Time: 7.15 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37280771136283875 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.37350699305534363 Time: 1.44 mn\n",
      "[20000/60000] Loss: 0.3732684552669525 Time: 2.86 mn\n",
      "[30000/60000] Loss: 0.37050560116767883 Time: 4.29 mn\n",
      "[40000/60000] Loss: 0.37066492438316345 Time: 5.71 mn\n",
      "[50000/60000] Loss: 0.37635624408721924 Time: 7.13 mn\n",
      "Training model... with lr= 0.009\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6934972405433655 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.6863564252853394 Time: 1.44 mn\n",
      "[20000/60000] Loss: 0.6791785359382629 Time: 2.86 mn\n",
      "[30000/60000] Loss: 0.6701770424842834 Time: 4.28 mn\n",
      "[40000/60000] Loss: 0.6584369540214539 Time: 5.70 mn\n",
      "[50000/60000] Loss: 0.6417655348777771 Time: 7.13 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6154242753982544 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.5749070048332214 Time: 1.44 mn\n",
      "[20000/60000] Loss: 0.519277036190033 Time: 2.87 mn\n",
      "[30000/60000] Loss: 0.45934635400772095 Time: 4.29 mn\n",
      "[40000/60000] Loss: 0.4100704491138458 Time: 5.71 mn\n",
      "[50000/60000] Loss: 0.3920508921146393 Time: 7.15 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3820425271987915 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3741397559642792 Time: 1.45 mn\n",
      "[20000/60000] Loss: 0.3790401816368103 Time: 2.87 mn\n",
      "[30000/60000] Loss: 0.3754146695137024 Time: 4.29 mn\n",
      "[40000/60000] Loss: 0.37580564618110657 Time: 5.71 mn\n",
      "[50000/60000] Loss: 0.3724820017814636 Time: 7.14 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3773595690727234 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36932653188705444 Time: 1.43 mn\n",
      "[20000/60000] Loss: 0.37198406457901 Time: 2.86 mn\n",
      "[30000/60000] Loss: 0.3732430040836334 Time: 4.28 mn\n",
      "[40000/60000] Loss: 0.3711097240447998 Time: 5.70 mn\n",
      "[50000/60000] Loss: 0.37369468808174133 Time: 7.14 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3719695508480072 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3789156973361969 Time: 1.44 mn\n",
      "[20000/60000] Loss: 0.37370067834854126 Time: 2.87 mn\n",
      "[30000/60000] Loss: 0.36965441703796387 Time: 4.27 mn\n",
      "[40000/60000] Loss: 0.3750588893890381 Time: 5.59 mn\n",
      "[50000/60000] Loss: 0.37420088052749634 Time: 6.91 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37575146555900574 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3719503879547119 Time: 1.00 mn\n",
      "[20000/60000] Loss: 0.3681950569152832 Time: 1.99 mn\n",
      "[30000/60000] Loss: 0.37149783968925476 Time: 2.97 mn\n",
      "[40000/60000] Loss: 0.3720581829547882 Time: 3.95 mn\n",
      "[50000/60000] Loss: 0.37076571583747864 Time: 4.93 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37650570273399353 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.37019336223602295 Time: 1.00 mn\n",
      "[20000/60000] Loss: 0.37014883756637573 Time: 1.99 mn\n",
      "[30000/60000] Loss: 0.3717673718929291 Time: 2.97 mn\n",
      "[40000/60000] Loss: 0.3706367015838623 Time: 3.96 mn\n",
      "[50000/60000] Loss: 0.37345677614212036 Time: 4.95 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37057676911354065 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3702419698238373 Time: 1.00 mn\n",
      "[20000/60000] Loss: 0.3702057898044586 Time: 1.99 mn\n",
      "[30000/60000] Loss: 0.37382078170776367 Time: 2.97 mn\n",
      "[40000/60000] Loss: 0.3701070249080658 Time: 3.96 mn\n",
      "[50000/60000] Loss: 0.3722359836101532 Time: 4.95 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36797818541526794 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3748985528945923 Time: 1.00 mn\n",
      "[20000/60000] Loss: 0.36916956305503845 Time: 1.98 mn\n",
      "[30000/60000] Loss: 0.3671448230743408 Time: 2.97 mn\n",
      "[40000/60000] Loss: 0.3691425621509552 Time: 3.96 mn\n",
      "[50000/60000] Loss: 0.3742079436779022 Time: 4.95 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37148720026016235 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.37567776441574097 Time: 1.00 mn\n",
      "[20000/60000] Loss: 0.3722599446773529 Time: 1.98 mn\n",
      "[30000/60000] Loss: 0.3695880174636841 Time: 2.97 mn\n",
      "[40000/60000] Loss: 0.37042391300201416 Time: 3.95 mn\n",
      "[50000/60000] Loss: 0.3739142119884491 Time: 4.94 mn\n",
      "Training model... with lr= 0.016\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.691095769405365 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.6785109043121338 Time: 0.99 mn\n",
      "[20000/60000] Loss: 0.6605657339096069 Time: 1.95 mn\n",
      "[30000/60000] Loss: 0.6263273358345032 Time: 2.92 mn\n",
      "[40000/60000] Loss: 0.5547271966934204 Time: 3.89 mn\n",
      "[50000/60000] Loss: 0.4505600333213806 Time: 4.87 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.39275163412094116 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.37756386399269104 Time: 0.98 mn\n",
      "[20000/60000] Loss: 0.3778038024902344 Time: 1.95 mn\n",
      "[30000/60000] Loss: 0.37859073281288147 Time: 2.92 mn\n",
      "[40000/60000] Loss: 0.3742838203907013 Time: 3.89 mn\n",
      "[50000/60000] Loss: 0.3758300840854645 Time: 4.87 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3675411343574524 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.37134188413619995 Time: 0.98 mn\n",
      "[20000/60000] Loss: 0.3722144663333893 Time: 1.96 mn\n",
      "[30000/60000] Loss: 0.36707374453544617 Time: 2.93 mn\n",
      "[40000/60000] Loss: 0.3705083727836609 Time: 3.90 mn\n",
      "[50000/60000] Loss: 0.3724997341632843 Time: 4.87 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3744330108165741 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.377594530582428 Time: 0.98 mn\n",
      "[20000/60000] Loss: 0.3686988651752472 Time: 1.96 mn\n",
      "[30000/60000] Loss: 0.3755967915058136 Time: 2.94 mn\n",
      "[40000/60000] Loss: 0.37009197473526 Time: 3.92 mn\n",
      "[50000/60000] Loss: 0.3694707155227661 Time: 4.89 mn\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/60000] Loss: 0.37219077348709106 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.37777939438819885 Time: 0.99 mn\n",
      "[20000/60000] Loss: 0.3724324405193329 Time: 1.96 mn\n",
      "[30000/60000] Loss: 0.3688524067401886 Time: 2.86 mn\n",
      "[40000/60000] Loss: 0.3745954930782318 Time: 3.76 mn\n",
      "[50000/60000] Loss: 0.3753197193145752 Time: 4.67 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3745695948600769 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.37136518955230713 Time: 0.91 mn\n",
      "[20000/60000] Loss: 0.37379711866378784 Time: 1.82 mn\n",
      "[30000/60000] Loss: 0.3684343695640564 Time: 2.73 mn\n",
      "[40000/60000] Loss: 0.3688509464263916 Time: 3.63 mn\n",
      "[50000/60000] Loss: 0.3765953481197357 Time: 4.55 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.369096577167511 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36826449632644653 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.3712029457092285 Time: 1.83 mn\n",
      "[30000/60000] Loss: 0.37020888924598694 Time: 2.74 mn\n",
      "[40000/60000] Loss: 0.3711845576763153 Time: 3.65 mn\n",
      "[50000/60000] Loss: 0.3768625855445862 Time: 4.55 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37654173374176025 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3748789131641388 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.37000805139541626 Time: 1.84 mn\n",
      "[30000/60000] Loss: 0.3710593283176422 Time: 2.76 mn\n",
      "[40000/60000] Loss: 0.3721393942832947 Time: 3.68 mn\n",
      "[50000/60000] Loss: 0.3691006004810333 Time: 4.59 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3713003695011139 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3755719065666199 Time: 0.93 mn\n",
      "[20000/60000] Loss: 0.36956894397735596 Time: 1.84 mn\n",
      "[30000/60000] Loss: 0.37121158838272095 Time: 2.76 mn\n",
      "[40000/60000] Loss: 0.36935633420944214 Time: 3.68 mn\n",
      "[50000/60000] Loss: 0.3704855740070343 Time: 4.59 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3732883334159851 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3643908202648163 Time: 0.93 mn\n",
      "[20000/60000] Loss: 0.37371864914894104 Time: 1.85 mn\n",
      "[30000/60000] Loss: 0.37283748388290405 Time: 2.77 mn\n",
      "[40000/60000] Loss: 0.3716300129890442 Time: 3.68 mn\n",
      "[50000/60000] Loss: 0.3718070387840271 Time: 4.59 mn\n",
      "Training model... with lr= 0.028\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6961524486541748 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.6734183430671692 Time: 0.93 mn\n",
      "[20000/60000] Loss: 0.6135788559913635 Time: 1.84 mn\n",
      "[30000/60000] Loss: 0.44211533665657043 Time: 2.76 mn\n",
      "[40000/60000] Loss: 0.379660427570343 Time: 3.67 mn\n",
      "[50000/60000] Loss: 0.37585756182670593 Time: 4.58 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3738463819026947 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.37096917629241943 Time: 0.93 mn\n",
      "[20000/60000] Loss: 0.3758374750614166 Time: 1.84 mn\n",
      "[30000/60000] Loss: 0.3733122944831848 Time: 2.76 mn\n",
      "[40000/60000] Loss: 0.3742907643318176 Time: 3.67 mn\n",
      "[50000/60000] Loss: 0.3684138357639313 Time: 4.58 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37144792079925537 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3678555488586426 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.37061598896980286 Time: 1.84 mn\n",
      "[30000/60000] Loss: 0.3698752522468567 Time: 2.76 mn\n",
      "[40000/60000] Loss: 0.37483489513397217 Time: 3.68 mn\n",
      "[50000/60000] Loss: 0.3709966540336609 Time: 4.59 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3705291748046875 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3687564730644226 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.36951902508735657 Time: 1.83 mn\n",
      "[30000/60000] Loss: 0.3724958002567291 Time: 2.75 mn\n",
      "[40000/60000] Loss: 0.37116965651512146 Time: 3.67 mn\n",
      "[50000/60000] Loss: 0.37287914752960205 Time: 4.59 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3700019419193268 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3681301176548004 Time: 0.93 mn\n",
      "[20000/60000] Loss: 0.3710762858390808 Time: 1.86 mn\n",
      "[30000/60000] Loss: 0.3689253330230713 Time: 2.78 mn\n",
      "[40000/60000] Loss: 0.3691712021827698 Time: 3.70 mn\n",
      "[50000/60000] Loss: 0.3740598261356354 Time: 4.62 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3702748119831085 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.37207674980163574 Time: 0.93 mn\n",
      "[20000/60000] Loss: 0.3665068745613098 Time: 1.85 mn\n",
      "[30000/60000] Loss: 0.36796846985816956 Time: 2.77 mn\n",
      "[40000/60000] Loss: 0.3723396360874176 Time: 3.69 mn\n",
      "[50000/60000] Loss: 0.3679809272289276 Time: 4.61 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3662882447242737 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36907386779785156 Time: 0.94 mn\n",
      "[20000/60000] Loss: 0.3658464848995209 Time: 1.86 mn\n",
      "[30000/60000] Loss: 0.3722737431526184 Time: 2.78 mn\n",
      "[40000/60000] Loss: 0.3673165440559387 Time: 3.70 mn\n",
      "[50000/60000] Loss: 0.375702828168869 Time: 4.62 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37216752767562866 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36796215176582336 Time: 0.94 mn\n",
      "[20000/60000] Loss: 0.37247076630592346 Time: 1.85 mn\n",
      "[30000/60000] Loss: 0.36999258399009705 Time: 2.77 mn\n",
      "[40000/60000] Loss: 0.3729507327079773 Time: 3.69 mn\n",
      "[50000/60000] Loss: 0.3669372797012329 Time: 4.61 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3761783838272095 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3699088990688324 Time: 0.93 mn\n",
      "[20000/60000] Loss: 0.37002161145210266 Time: 1.84 mn\n",
      "[30000/60000] Loss: 0.36903151869773865 Time: 2.76 mn\n",
      "[40000/60000] Loss: 0.36865130066871643 Time: 3.68 mn\n",
      "[50000/60000] Loss: 0.37111160159111023 Time: 4.60 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36923155188560486 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3716713488101959 Time: 0.93 mn\n",
      "[20000/60000] Loss: 0.3717364966869354 Time: 1.86 mn\n",
      "[30000/60000] Loss: 0.37228065729141235 Time: 2.79 mn\n",
      "[40000/60000] Loss: 0.3698681592941284 Time: 3.71 mn\n",
      "[50000/60000] Loss: 0.37084031105041504 Time: 4.63 mn\n",
      "Training model... with lr= 0.050\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6948941946029663 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.6289328932762146 Time: 0.93 mn\n",
      "[20000/60000] Loss: 0.382596492767334 Time: 1.85 mn\n",
      "[30000/60000] Loss: 0.3698476552963257 Time: 2.76 mn\n",
      "[40000/60000] Loss: 0.37160155177116394 Time: 3.68 mn\n",
      "[50000/60000] Loss: 0.37239694595336914 Time: 4.59 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37179529666900635 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3734562397003174 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.37019720673561096 Time: 1.84 mn\n",
      "[30000/60000] Loss: 0.3704916834831238 Time: 2.75 mn\n",
      "[40000/60000] Loss: 0.372643381357193 Time: 3.67 mn\n",
      "[50000/60000] Loss: 0.37115445733070374 Time: 4.59 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37467172741889954 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.37239208817481995 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.3700844347476959 Time: 1.85 mn\n",
      "[30000/60000] Loss: 0.3734210431575775 Time: 2.77 mn\n",
      "[40000/60000] Loss: 0.36889246106147766 Time: 3.69 mn\n",
      "[50000/60000] Loss: 0.372714102268219 Time: 4.60 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.368961364030838 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36480140686035156 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.36999964714050293 Time: 1.82 mn\n",
      "[30000/60000] Loss: 0.3707548975944519 Time: 2.73 mn\n",
      "[40000/60000] Loss: 0.36914268136024475 Time: 3.64 mn\n",
      "[50000/60000] Loss: 0.3671947717666626 Time: 4.55 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3700336515903473 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.37112757563591003 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.3682939112186432 Time: 1.83 mn\n",
      "[30000/60000] Loss: 0.36804500222206116 Time: 2.74 mn\n",
      "[40000/60000] Loss: 0.3710823357105255 Time: 3.65 mn\n",
      "[50000/60000] Loss: 0.36944499611854553 Time: 4.57 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36468204855918884 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36804306507110596 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.36649709939956665 Time: 1.83 mn\n",
      "[30000/60000] Loss: 0.3653205633163452 Time: 2.74 mn\n",
      "[40000/60000] Loss: 0.3672359585762024 Time: 3.64 mn\n",
      "[50000/60000] Loss: 0.36985352635383606 Time: 4.55 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3640061318874359 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3663162589073181 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.3657301068305969 Time: 1.82 mn\n",
      "[30000/60000] Loss: 0.36693650484085083 Time: 2.73 mn\n",
      "[40000/60000] Loss: 0.36406391859054565 Time: 3.64 mn\n",
      "[50000/60000] Loss: 0.37012508511543274 Time: 4.54 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36743998527526855 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36780455708503723 Time: 0.91 mn\n",
      "[20000/60000] Loss: 0.36343562602996826 Time: 1.82 mn\n",
      "[30000/60000] Loss: 0.36750277876853943 Time: 2.73 mn\n",
      "[40000/60000] Loss: 0.3683575391769409 Time: 3.64 mn\n",
      "[50000/60000] Loss: 0.36451107263565063 Time: 4.56 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3700666129589081 Time: 0.01 mn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000/60000] Loss: 0.36823394894599915 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.36632296442985535 Time: 1.84 mn\n",
      "[30000/60000] Loss: 0.3679659068584442 Time: 2.75 mn\n",
      "[40000/60000] Loss: 0.3654194474220276 Time: 3.67 mn\n",
      "[50000/60000] Loss: 0.36739927530288696 Time: 4.59 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36734509468078613 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36773714423179626 Time: 0.93 mn\n",
      "[20000/60000] Loss: 0.3670283555984497 Time: 1.84 mn\n",
      "[30000/60000] Loss: 0.3640797436237335 Time: 2.75 mn\n",
      "[40000/60000] Loss: 0.36727142333984375 Time: 3.67 mn\n",
      "[50000/60000] Loss: 0.37157127261161804 Time: 4.59 mn\n",
      "Training model... with lr= 0.089\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6949862837791443 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.4746299386024475 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.3741247355937958 Time: 1.83 mn\n",
      "[30000/60000] Loss: 0.37198442220687866 Time: 2.74 mn\n",
      "[40000/60000] Loss: 0.3746742010116577 Time: 3.66 mn\n",
      "[50000/60000] Loss: 0.37414848804473877 Time: 4.57 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37159889936447144 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.37152624130249023 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.37081798911094666 Time: 1.83 mn\n",
      "[30000/60000] Loss: 0.3681895136833191 Time: 2.74 mn\n",
      "[40000/60000] Loss: 0.3704972267150879 Time: 3.67 mn\n",
      "[50000/60000] Loss: 0.3683079183101654 Time: 4.60 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3759557902812958 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3637629449367523 Time: 0.94 mn\n",
      "[20000/60000] Loss: 0.36704927682876587 Time: 1.88 mn\n",
      "[30000/60000] Loss: 0.3692585229873657 Time: 2.81 mn\n",
      "[40000/60000] Loss: 0.37149322032928467 Time: 3.73 mn\n",
      "[50000/60000] Loss: 0.3675119876861572 Time: 4.65 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37447190284729004 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3728892505168915 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.36763644218444824 Time: 1.83 mn\n",
      "[30000/60000] Loss: 0.37196028232574463 Time: 2.73 mn\n",
      "[40000/60000] Loss: 0.36599892377853394 Time: 3.65 mn\n",
      "[50000/60000] Loss: 0.3663141429424286 Time: 4.56 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36939483880996704 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3689902126789093 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.36722317337989807 Time: 1.82 mn\n",
      "[30000/60000] Loss: 0.36640864610671997 Time: 2.73 mn\n",
      "[40000/60000] Loss: 0.37051862478256226 Time: 3.64 mn\n",
      "[50000/60000] Loss: 0.3679584562778473 Time: 4.55 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3690115809440613 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3684535026550293 Time: 0.93 mn\n",
      "[20000/60000] Loss: 0.36467260122299194 Time: 1.84 mn\n",
      "[30000/60000] Loss: 0.36574500799179077 Time: 2.75 mn\n",
      "[40000/60000] Loss: 0.3631491959095001 Time: 3.66 mn\n",
      "[50000/60000] Loss: 0.36449190974235535 Time: 4.57 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36768394708633423 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3651297688484192 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.3641152083873749 Time: 1.83 mn\n",
      "[30000/60000] Loss: 0.3675422966480255 Time: 2.74 mn\n",
      "[40000/60000] Loss: 0.36264970898628235 Time: 3.65 mn\n",
      "[50000/60000] Loss: 0.364358514547348 Time: 4.56 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36658188700675964 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36767128109931946 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.3624112904071808 Time: 1.83 mn\n",
      "[30000/60000] Loss: 0.36512696743011475 Time: 2.74 mn\n",
      "[40000/60000] Loss: 0.36370909214019775 Time: 3.66 mn\n",
      "[50000/60000] Loss: 0.36990123987197876 Time: 4.57 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36566340923309326 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36395472288131714 Time: 0.91 mn\n",
      "[20000/60000] Loss: 0.36174076795578003 Time: 1.83 mn\n",
      "[30000/60000] Loss: 0.36695581674575806 Time: 2.75 mn\n",
      "[40000/60000] Loss: 0.36186185479164124 Time: 3.66 mn\n",
      "[50000/60000] Loss: 0.36303290724754333 Time: 4.57 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.366520494222641 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36229953169822693 Time: 0.93 mn\n",
      "[20000/60000] Loss: 0.36350521445274353 Time: 1.84 mn\n",
      "[30000/60000] Loss: 0.3609493672847748 Time: 2.75 mn\n",
      "[40000/60000] Loss: 0.3657975494861603 Time: 3.66 mn\n",
      "[50000/60000] Loss: 0.3634335994720459 Time: 4.57 mn\n",
      "Training model... with lr= 0.158\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6937336325645447 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.373857319355011 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.36756300926208496 Time: 1.83 mn\n",
      "[30000/60000] Loss: 0.37047716975212097 Time: 2.74 mn\n",
      "[40000/60000] Loss: 0.37200823426246643 Time: 3.66 mn\n",
      "[50000/60000] Loss: 0.36580830812454224 Time: 4.56 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.37180453538894653 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3690153956413269 Time: 0.91 mn\n",
      "[20000/60000] Loss: 0.36988452076911926 Time: 1.81 mn\n",
      "[30000/60000] Loss: 0.36488741636276245 Time: 2.71 mn\n",
      "[40000/60000] Loss: 0.37270545959472656 Time: 3.60 mn\n",
      "[50000/60000] Loss: 0.36560678482055664 Time: 4.51 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3711382746696472 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36886146664619446 Time: 0.91 mn\n",
      "[20000/60000] Loss: 0.3715516924858093 Time: 1.81 mn\n",
      "[30000/60000] Loss: 0.36394768953323364 Time: 2.71 mn\n",
      "[40000/60000] Loss: 0.368935763835907 Time: 3.60 mn\n",
      "[50000/60000] Loss: 0.3710464835166931 Time: 4.49 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36664536595344543 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3646320104598999 Time: 0.91 mn\n",
      "[20000/60000] Loss: 0.3626609742641449 Time: 1.81 mn\n",
      "[30000/60000] Loss: 0.36582255363464355 Time: 2.71 mn\n",
      "[40000/60000] Loss: 0.36322784423828125 Time: 3.61 mn\n",
      "[50000/60000] Loss: 0.36743223667144775 Time: 4.53 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36184456944465637 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36350059509277344 Time: 0.93 mn\n",
      "[20000/60000] Loss: 0.36379775404930115 Time: 1.85 mn\n",
      "[30000/60000] Loss: 0.3617177903652191 Time: 2.76 mn\n",
      "[40000/60000] Loss: 0.3629455268383026 Time: 3.68 mn\n",
      "[50000/60000] Loss: 0.3619863986968994 Time: 4.59 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.364663302898407 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36216825246810913 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.359596848487854 Time: 1.83 mn\n",
      "[30000/60000] Loss: 0.35740339756011963 Time: 2.75 mn\n",
      "[40000/60000] Loss: 0.36529308557510376 Time: 3.67 mn\n",
      "[50000/60000] Loss: 0.3585035502910614 Time: 4.58 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36112180352211 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.359945684671402 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.3626655340194702 Time: 1.84 mn\n",
      "[30000/60000] Loss: 0.36076128482818604 Time: 2.75 mn\n",
      "[40000/60000] Loss: 0.3628254234790802 Time: 3.67 mn\n",
      "[50000/60000] Loss: 0.36457663774490356 Time: 4.58 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3648355007171631 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36200523376464844 Time: 0.93 mn\n",
      "[20000/60000] Loss: 0.36262112855911255 Time: 1.84 mn\n",
      "[30000/60000] Loss: 0.3588419556617737 Time: 2.74 mn\n",
      "[40000/60000] Loss: 0.35979974269866943 Time: 3.66 mn\n",
      "[50000/60000] Loss: 0.36051324009895325 Time: 4.58 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36278656125068665 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3601256310939789 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.36062777042388916 Time: 1.83 mn\n",
      "[30000/60000] Loss: 0.36669957637786865 Time: 2.75 mn\n",
      "[40000/60000] Loss: 0.35981690883636475 Time: 3.65 mn\n",
      "[50000/60000] Loss: 0.36169174313545227 Time: 4.56 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3598479926586151 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3596669137477875 Time: 0.92 mn\n",
      "[20000/60000] Loss: 0.3632012903690338 Time: 1.82 mn\n",
      "[30000/60000] Loss: 0.36236879229545593 Time: 2.73 mn\n",
      "[40000/60000] Loss: 0.3611913025379181 Time: 3.64 mn\n",
      "[50000/60000] Loss: 0.36147403717041016 Time: 4.56 mn\n",
      "Training model... with lr= 0.281\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6960442066192627 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3699839413166046 Time: 0.91 mn\n",
      "[20000/60000] Loss: 0.3711234927177429 Time: 1.82 mn\n",
      "[30000/60000] Loss: 0.36717793345451355 Time: 2.72 mn\n",
      "[40000/60000] Loss: 0.3668932020664215 Time: 3.64 mn\n",
      "[50000/60000] Loss: 0.3673704266548157 Time: 4.55 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3683550953865051 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.37042322754859924 Time: 0.91 mn\n",
      "[20000/60000] Loss: 0.36697444319725037 Time: 1.74 mn\n",
      "[30000/60000] Loss: 0.3685654401779175 Time: 2.58 mn\n",
      "[40000/60000] Loss: 0.3681055009365082 Time: 3.42 mn\n",
      "[50000/60000] Loss: 0.36777693033218384 Time: 4.25 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36467576026916504 Time: 0.01 mn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000/60000] Loss: 0.3625882863998413 Time: 0.85 mn\n",
      "[20000/60000] Loss: 0.3651469945907593 Time: 1.69 mn\n",
      "[30000/60000] Loss: 0.3638099133968353 Time: 2.52 mn\n",
      "[40000/60000] Loss: 0.3628079295158386 Time: 3.36 mn\n",
      "[50000/60000] Loss: 0.36328962445259094 Time: 4.20 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3631555140018463 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3634202480316162 Time: 0.85 mn\n",
      "[20000/60000] Loss: 0.3605213463306427 Time: 1.68 mn\n",
      "[30000/60000] Loss: 0.3628930151462555 Time: 2.52 mn\n",
      "[40000/60000] Loss: 0.3599123954772949 Time: 3.35 mn\n",
      "[50000/60000] Loss: 0.35776883363723755 Time: 4.19 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3629375398159027 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3608863651752472 Time: 0.85 mn\n",
      "[20000/60000] Loss: 0.36511754989624023 Time: 1.68 mn\n",
      "[30000/60000] Loss: 0.3615639805793762 Time: 2.52 mn\n",
      "[40000/60000] Loss: 0.3605625629425049 Time: 3.36 mn\n",
      "[50000/60000] Loss: 0.3643968105316162 Time: 4.19 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36320623755455017 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36025679111480713 Time: 0.84 mn\n",
      "[20000/60000] Loss: 0.36277469992637634 Time: 1.68 mn\n",
      "[30000/60000] Loss: 0.3615274727344513 Time: 2.51 mn\n",
      "[40000/60000] Loss: 0.35996851325035095 Time: 3.34 mn\n",
      "[50000/60000] Loss: 0.3605659306049347 Time: 4.18 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.359372079372406 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3618829548358917 Time: 0.84 mn\n",
      "[20000/60000] Loss: 0.35654670000076294 Time: 1.68 mn\n",
      "[30000/60000] Loss: 0.3599840998649597 Time: 2.52 mn\n",
      "[40000/60000] Loss: 0.35957592725753784 Time: 3.35 mn\n",
      "[50000/60000] Loss: 0.3642243444919586 Time: 4.19 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3599713146686554 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3620735704898834 Time: 0.84 mn\n",
      "[20000/60000] Loss: 0.3623696565628052 Time: 1.68 mn\n",
      "[30000/60000] Loss: 0.359571248292923 Time: 2.51 mn\n",
      "[40000/60000] Loss: 0.36002397537231445 Time: 3.35 mn\n",
      "[50000/60000] Loss: 0.361576646566391 Time: 4.18 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36240968108177185 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3628924489021301 Time: 0.84 mn\n",
      "[20000/60000] Loss: 0.3630523681640625 Time: 1.68 mn\n",
      "[30000/60000] Loss: 0.36500605940818787 Time: 2.52 mn\n",
      "[40000/60000] Loss: 0.3622332811355591 Time: 3.36 mn\n",
      "[50000/60000] Loss: 0.3601842522621155 Time: 4.20 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3611932098865509 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3621279299259186 Time: 0.85 mn\n",
      "[20000/60000] Loss: 0.36157655715942383 Time: 1.69 mn\n",
      "[30000/60000] Loss: 0.3623746931552887 Time: 2.52 mn\n",
      "[40000/60000] Loss: 0.3606993556022644 Time: 3.36 mn\n",
      "[50000/60000] Loss: 0.36426594853401184 Time: 4.19 mn\n",
      "Training model... with lr= 0.500\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.6916424036026001 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3663179874420166 Time: 0.85 mn\n",
      "[20000/60000] Loss: 0.37144070863723755 Time: 1.69 mn\n",
      "[30000/60000] Loss: 0.36857789754867554 Time: 2.52 mn\n",
      "[40000/60000] Loss: 0.365774542093277 Time: 3.36 mn\n",
      "[50000/60000] Loss: 0.3674316108226776 Time: 4.19 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3649115264415741 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36631280183792114 Time: 0.84 mn\n",
      "[20000/60000] Loss: 0.3639763295650482 Time: 1.68 mn\n",
      "[30000/60000] Loss: 0.36488381028175354 Time: 2.52 mn\n",
      "[40000/60000] Loss: 0.36446383595466614 Time: 3.35 mn\n",
      "[50000/60000] Loss: 0.361013263463974 Time: 4.19 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3614013195037842 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3602571189403534 Time: 0.84 mn\n",
      "[20000/60000] Loss: 0.36701399087905884 Time: 1.68 mn\n",
      "[30000/60000] Loss: 0.3600611984729767 Time: 2.51 mn\n",
      "[40000/60000] Loss: 0.36078691482543945 Time: 3.35 mn\n",
      "[50000/60000] Loss: 0.35820263624191284 Time: 4.18 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36379221081733704 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.35968855023384094 Time: 0.84 mn\n",
      "[20000/60000] Loss: 0.36088886857032776 Time: 1.68 mn\n",
      "[30000/60000] Loss: 0.3628203570842743 Time: 2.51 mn\n",
      "[40000/60000] Loss: 0.362272709608078 Time: 3.35 mn\n",
      "[50000/60000] Loss: 0.3604514002799988 Time: 4.19 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3617565929889679 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3620655834674835 Time: 0.84 mn\n",
      "[20000/60000] Loss: 0.3584785759449005 Time: 1.68 mn\n",
      "[30000/60000] Loss: 0.36195117235183716 Time: 2.52 mn\n",
      "[40000/60000] Loss: 0.3606051206588745 Time: 3.36 mn\n",
      "[50000/60000] Loss: 0.36076620221138 Time: 4.20 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.36191102862358093 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3624323904514313 Time: 0.79 mn\n",
      "[20000/60000] Loss: 0.3589681088924408 Time: 1.55 mn\n",
      "[30000/60000] Loss: 0.3590622842311859 Time: 2.32 mn\n",
      "[40000/60000] Loss: 0.3599471151828766 Time: 3.05 mn\n",
      "[50000/60000] Loss: 0.35763758420944214 Time: 3.77 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3612263798713684 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3614567816257477 Time: 0.73 mn\n",
      "[20000/60000] Loss: 0.362424373626709 Time: 1.45 mn\n",
      "[30000/60000] Loss: 0.36194825172424316 Time: 2.18 mn\n",
      "[40000/60000] Loss: 0.3579804003238678 Time: 2.90 mn\n",
      "[50000/60000] Loss: 0.36065271496772766 Time: 3.62 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3563063442707062 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3578786253929138 Time: 0.73 mn\n",
      "[20000/60000] Loss: 0.36123937368392944 Time: 1.45 mn\n",
      "[30000/60000] Loss: 0.3601457476615906 Time: 2.18 mn\n",
      "[40000/60000] Loss: 0.35688862204551697 Time: 2.90 mn\n",
      "[50000/60000] Loss: 0.3593166172504425 Time: 3.62 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.3570466637611389 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.36045050621032715 Time: 0.73 mn\n",
      "[20000/60000] Loss: 0.3613455593585968 Time: 1.43 mn\n",
      "[30000/60000] Loss: 0.36477556824684143 Time: 2.08 mn\n",
      "[40000/60000] Loss: 0.35881248116493225 Time: 2.73 mn\n",
      "[50000/60000] Loss: 0.365073561668396 Time: 3.39 mn\n",
      "Starting training...\n",
      "[0/60000] Loss: 0.35791465640068054 Time: 0.01 mn\n",
      "[10000/60000] Loss: 0.3574884533882141 Time: 0.66 mn\n",
      "[20000/60000] Loss: 0.35554301738739014 Time: 1.31 mn\n",
      "[30000/60000] Loss: 0.35672852396965027 Time: 1.97 mn\n",
      "[40000/60000] Loss: 0.36328548192977905 Time: 2.62 mn\n",
      "[50000/60000] Loss: 0.3608478903770447 Time: 3.27 mn\n"
     ]
    }
   ],
   "source": [
    "for lr_ in lr*np.logspace(-1, 1, 9, base=10):\n",
    "    net = Net(n_feature=N_theta*N_azimuth*N_eccentricty*N_phase, n_hidden1=n_hidden1, n_hidden2=n_hidden2, n_output=N_azimuth*N_eccentricty)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr_)\n",
    "    loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    print('Training model... with lr=', '%.3f' % lr_)\n",
    "    N_epochs = 10\n",
    "    for epoch in range(N_epochs):          #max number of training epochs\n",
    "        train(net, minibatch_size, optimizer=optimizer)                 #starting the learning\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
