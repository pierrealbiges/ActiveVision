{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import noise\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import MotionClouds as mc\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from LogGabor import LogGabor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charger la matrice de certitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading accuracy...\n",
      "[[ 0.0974  0.0974  0.0974 ...,  0.0974  0.0974  0.0974]\n",
      " [ 0.0974  0.0974  0.0974 ...,  0.0974  0.0974  0.0974]\n",
      " [ 0.0974  0.0974  0.0974 ...,  0.0974  0.0974  0.0974]\n",
      " ..., \n",
      " [ 0.0974  0.0974  0.0974 ...,  0.0974  0.0974  0.0974]\n",
      " [ 0.0974  0.0974  0.0974 ...,  0.0974  0.0974  0.0974]\n",
      " [ 0.0974  0.0974  0.0974 ...,  0.0974  0.0974  0.0974]]\n"
     ]
    }
   ],
   "source": [
    "path = \"MNIST_accuracy.npy\"\n",
    "if os.path.isfile(path):\n",
    "    print('Loading accuracy...')\n",
    "    accuracy =  np.load(path)\n",
    "    print(accuracy)\n",
    "else:\n",
    "    print('No accuracy data found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparer l'apprentissage et les fonctions nécessaires au fonctionnement du script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization(N_theta, N_orient, N_scale, N_phase, N_X, N_Y, rho):\n",
    "    phi = np.zeros((N_theta, N_orient, N_scale, N_phase, N_X*N_Y))\n",
    "    parameterfile = 'https://raw.githubusercontent.com/bicv/LogGabor/master/default_param.py'\n",
    "    lg = LogGabor(parameterfile)\n",
    "    lg.set_size((N_X, N_Y))\n",
    "    params= {'sf_0':.1, 'B_sf': lg.pe.B_sf, 'theta':np.pi* 5 / 7., 'B_theta': lg.pe.B_theta}\n",
    "    phase = np.pi/4\n",
    "    edge = lg.normalize(lg.invert(lg.loggabor(N_X/3, 3*N_Y/4, **params)*np.exp(-1j*phase)))\n",
    "    \n",
    "    for i_theta in range(N_theta):\n",
    "        for i_orient in range(N_orient):\n",
    "            for i_scale in range(N_scale):\n",
    "                ecc =  (1/rho)**(N_scale - i_scale)\n",
    "                r = np.sqrt(N_X**2+N_Y**2) / 2 * ecc # radius\n",
    "                sf_0 = 0.5 * 0.03 / ecc\n",
    "                x = N_X/2 + r * np.cos((i_orient+(i_scale % 2)*.5)*np.pi*2 / N_orient)\n",
    "                y = N_Y/2 + r * np.sin((i_orient+(i_scale % 2)*.5)*np.pi*2 / N_orient)            \n",
    "                for i_phase in range(N_phase):\n",
    "                    params= {'sf_0':sf_0, 'B_sf': lg.pe.B_sf, 'theta':i_theta*np.pi/N_theta, 'B_theta': np.pi/N_theta/2}\n",
    "                    phase = i_phase * np.pi/2\n",
    "                    phi[i_theta, i_orient, i_scale, i_phase, :] = lg.normalize(lg.invert(lg.loggabor(x, y, **params)*np.exp(-1j*phase))).ravel()            \n",
    "    return phi\n",
    "\n",
    "N_theta, N_orient, N_scale, N_phase, N_X, N_Y, rho = 6, 12, 5, 2, 128, 128, 1.95\n",
    "phi = vectorization(N_theta, N_orient, N_scale, N_phase, N_X, N_Y, rho)\n",
    "phi_vector = phi.reshape((N_theta*N_orient*N_scale*N_phase, N_X*N_Y))\n",
    "phi_plus = np.linalg.pinv(phi_vector)\n",
    "\n",
    "energy = (phi**2).sum(axis=(0,3)) \n",
    "energy /= energy.sum(axis=-1)[:, :, None]\n",
    "energy_vector = energy.reshape((N_orient*N_scale, N_X*N_Y))\n",
    "energy_plus = np.linalg.pinv(energy_vector)\n",
    "\n",
    "def accuracy_128(i_offset, j_offset, N_pic=128, N_stim=55):\n",
    "    center = (N_pic-N_stim)//2\n",
    "    \n",
    "    accuracy_128 = 0.1 * np.ones((N_pic,N_pic))\n",
    "    accuracy_128[(center+i_offset):(center+N_stim+i_offset),(center+j_offset):(center+N_stim+j_offset)] = accuracy\n",
    "    \n",
    "    accuracy_LP = energy_vector @ np.ravel(accuracy_128)    \n",
    "    return accuracy_LP\n",
    "\n",
    "def mnist_128(data, i_offset, j_offset, N_pic=128, N_stim=28, noise=True, noise_type='MotionCloud'):\n",
    "    center = (N_pic-N_stim)//2\n",
    "    \n",
    "    data_128 = data.min() * np.ones((N_pic,N_pic))\n",
    "    data_128[(center+i_offset):(center+N_stim+i_offset),(center+j_offset):(center+N_stim+j_offset)] = data\n",
    "    \n",
    "    if noise:\n",
    "        if noise_type == 'MotionCloud':\n",
    "            data_LP = phi_vector @ np.ravel(data_128 + MotionCloudNoise())\n",
    "        elif noise_type == 'Perlin':\n",
    "            data_LP = phi_vector @ np.ravel(data_128 + randomized_perlin_noise())     \n",
    "    else:\n",
    "        data_LP = phi_vector @ np.ravel(data_128)     \n",
    "    return data_LP\n",
    "\n",
    "def couples(data, i_offset, j_offset):\n",
    "    v = mnist_128(data, i_offset, j_offset)\n",
    "    a = accuracy_128(i_offset, j_offset)    \n",
    "    return (v, a)\n",
    "\n",
    "def minmax(value, border):\n",
    "    value = max(value, -border)\n",
    "    value = min(value, border)\n",
    "    return value\n",
    "\n",
    "def sigmoid(values):\n",
    "    values = 1 / (1 + ((1 / 0.1) - 1) * np.exp(-values))\n",
    "    return values\n",
    "\n",
    "def randomized_perlin_noise(shape=(128,128), scale=10, octaves=6, persistence=0.5, lacunarity=2.0, base=0):\n",
    "    noise_vector = np.zeros(shape)\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            noise_vector[i][j] = noise.pnoise2(i/scale,\n",
    "                                        j/scale,\n",
    "                                        octaves=int(octave * abs(np.random.randn()))+1,\n",
    "                                        persistence=persistence * abs(np.random.randn()),\n",
    "                                        lacunarity=lacunarity * abs(np.random.randn()),\n",
    "                                        repeatx=shape[0], \n",
    "                                        repeaty=shape[1], \n",
    "                                        base=base)           \n",
    "    return noise_vector\n",
    "\n",
    "def MotionCloudNoise(sf_0=0.125, B_sf=3.):\n",
    "    mc.N_X, mc.N_Y, mc.N_frame = 128, 128, 1\n",
    "    fx, fy, ft = mc.get_grids(mc.N_X, mc.N_Y, mc.N_frame)\n",
    "    name = 'static'\n",
    "    env = mc.envelope_gabor(fx, fy, ft, sf_0=sf_0, B_sf=B_sf, B_theta=np.inf, V_X=0., V_Y=0., B_V=0, alpha=.5)\n",
    "    \n",
    "    z = mc.rectif(mc.random_cloud(env))\n",
    "    z = z.reshape((mc.N_X, mc.N_Y))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100 #quantity of examples that'll be processed\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('/tmp/data', \n",
    "                   train=True,    #def the dataset as training data \n",
    "                   download=True, #download if dataset not present on disk\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "                   batch_size=sample_size, \n",
    "                   shuffle=True)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden1, n_RNN, n_hidden2, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(n_feature, n_hidden1)\n",
    "        self.RNN = torch.nn.RNN(n_hidden1, n_RNN, nonlinearity='relu', bias=True, bidirectional=False)\n",
    "        self.hidden2 = torch.nn.Linear(n_RNN, n_hidden2)\n",
    "        self.predict = torch.nn.Linear(n_hidden2, n_output)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        data = F.leaky_relu(self.hidden1(data))\n",
    "        data, weights = self.RNN(data)\n",
    "        data = F.leaky_relu(self.hidden2(data))\n",
    "        data = self.predict(data)\n",
    "        data = F.softmax(data)\n",
    "        return data\n",
    "    \n",
    "net = Net(n_feature=720, n_hidden1=585, n_RNN=390, n_hidden2=195, n_output=60)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.3)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(sample_size, vsize=720, asize=60):\n",
    "    t_start = time.time()\n",
    "    print('Starting training...')\n",
    "    for batch_idx, (data, label) in enumerate(data_loader):\n",
    "        input, a_data = np.zeros((sample_size, 1, vsize)), np.zeros((sample_size, 1, asize))\n",
    "        target = np.zeros((sample_size, asize))\n",
    "        for idx in range(sample_size):\n",
    "            i_offset, j_offset = int(minmax(np.random.randn()*5, 35)), int(minmax(np.random.randn()*5, 35))\n",
    "            input[idx,0,:], a_data[idx,0,:] = couples(data[idx,0,:], i_offset, j_offset)\n",
    "            target[idx,:] = a_data[idx,0,:]\n",
    "\n",
    "        input, a_data = Variable(torch.FloatTensor(input)), Variable(torch.FloatTensor(a_data))\n",
    "        target = Variable(torch.LongTensor(target))\n",
    "\n",
    "        prediction = net(input)\n",
    "        loss = loss_func(prediction, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Epoch {}: [{}/{}] Loss: {} Time: {:.2f} mn'.format(\n",
    "                epoch, batch_idx*sample_size, len(data_loader.dataset), \n",
    "                loss.data.numpy(), (time.time()-t_start)/60))\n",
    "    \n",
    "def eval_sacc(vsize=720, asize=60, N_pic=128, sacc_lim=5, fovea_size=10, fig_type='cmap'):\n",
    "    for batch_idx, (data, label) in enumerate(data_loader):\n",
    "        i_offset, j_offset = int(minmax(np.random.randn()*10, 35)), int(minmax(np.random.randn()*10, 35))\n",
    "        print('Stimulus position: ({},{})'.format(i_offset, j_offset))\n",
    "        a_data_in_fovea = False\n",
    "        sacc_count = 0\n",
    "        \n",
    "        while not a_data_in_fovea:\n",
    "            input, a_data = np.zeros((1, 1, vsize)), np.zeros((1, 1, asize))\n",
    "            input[0,0,:], a_data[0,0,:] = couples(data[0,0,:], i_offset, j_offset)\n",
    "            input, a_data = Variable(torch.FloatTensor(input)), Variable(torch.FloatTensor(a_data))\n",
    "\n",
    "            prediction = net(input)        \n",
    "            pred_data = prediction.data.numpy()[-1][-1]\n",
    "\n",
    "            if fig_type == 'cmap':\n",
    "                image = sigmoid(energy_plus @ pred_data)\n",
    "                image_reshaped = image.reshape(N_pic,N_pic)\n",
    "\n",
    "                fig, ax = plt.subplots(figsize=(13,10.725))\n",
    "                cmap = ax.pcolor(np.arange(-(N_pic/2),(N_pic/2)), np.arange(-(N_pic/2),(N_pic/2)), image_reshaped)\n",
    "                fig.colorbar(cmap)\n",
    "                plt.axvline(j_offset, c='k'); plt.axhline(i_offset, c='k')\n",
    "                \n",
    "                for i_pred in range(0,N_pic):\n",
    "                    for j_pred in range(0,N_pic):\n",
    "                        if image_reshaped[i_pred][j_pred] == image_reshaped.max():\n",
    "                            i_hat, j_hat = i_pred-(N_pic/2), j_pred-(N_pic/2)\n",
    "                            print('Position prediction: ({},{})'.format(i_hat, j_hat))\n",
    "                            if fig_type == 'cmap':\n",
    "                                plt.axvline(j_hat, c='r'); plt.axhline(i_hat, c='r')\n",
    "                            break\n",
    "\n",
    "                #check if number of saccades is beyond threshold   \n",
    "                if sacc_count == sacc_lim:\n",
    "                    print('Stimulus position not found, break')\n",
    "                    break\n",
    "\n",
    "                #saccades\n",
    "                i_offset, j_offset = (i_offset - i_hat), (j_offset - j_hat)\n",
    "                sacc_count += 1\n",
    "                print('Stimulus position after saccade: ({}, {})'.format(i_offset, j_offset))\n",
    "                \n",
    "                #check if the image position is predicted within the fovea\n",
    "                if i_hat <= (fovea_size/2) and j_hat <= (fovea_size/2):\n",
    "                    if i_hat >= -(fovea_size/2) and j_hat >= -(fovea_size/2):\n",
    "                        a_data_in_fovea = True\n",
    "                        print('a_data predicted in fovea, stopping the saccadic exploration')\n",
    "            \n",
    "            if fig_type == 'log':\n",
    "                code = energy_plus @ np.ravel(pred_data)\n",
    "                code = phi @ code\n",
    "                global_energy = (code**2).sum(axis=(0, -1))\n",
    "                \n",
    "                log_r_a_data = 1 + np.log(np.sqrt(i_offset**2 + j_offset**2) / np.sqrt(N_X**2 + N_Y**2) / 2) / 5\n",
    "                if j_offset != 0:\n",
    "                    theta_a_data = np.arctan(-i_offset / j_offset)\n",
    "                else:\n",
    "                    theta_a_data = np.sign(-i_offset) * np.pi/2\n",
    "                print('a_data position (log_r, theta) = ({},{})'.format(log_r_a_data, theta_a_data))\n",
    "                log_r, theta = np.meshgrid(np.linspace(0, 1, N_scale+1), np.linspace(-np.pi*.625, np.pi*1.375, N_orient+1))\n",
    "\n",
    "                fig, ax = plt.subplots(subplot_kw=dict(projection='polar'))\n",
    "                ax.pcolor(theta, log_r, np.fliplr(global_energy))\n",
    "                ax.plot(theta_a_data, log_r_a_data, 'r+')\n",
    "                \n",
    "                for n_orient in range(N_orient):\n",
    "                    for n_scale in range(N_scale):\n",
    "                        if global_energy[n_orient][n_scale] == np.max(global_energy):\n",
    "                            print('Position prediction (orient, scale) = ({},{})'.format(n_orient, n_scale))\n",
    "                \n",
    "                a_data_in_fovea = True\n",
    "        \n",
    "        print('*' * 50)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancer l'apprentissage ou charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Starting training...\n",
      "Epoch 0: [0/60000] Loss: [ 0.] Time: 0.05 mn\n",
      "Epoch 0: [10000/60000] Loss: [ 0.] Time: 3.67 mn\n",
      "Epoch 0: [20000/60000] Loss: [ 0.] Time: 7.24 mn\n"
     ]
    }
   ],
   "source": [
    "path = 'regression_cross_entropy.pt'\n",
    "\n",
    "if os.path.isfile(path):\n",
    "    net.load_state_dict(torch.load(path))\n",
    "    print('Loading file', path)\n",
    "else:\n",
    "    print('Training model...')\n",
    "    for epoch in range(3):                 #max number of training epochs\n",
    "        train(sample_size)                 #starting the learning\n",
    "        torch.save(net.state_dict(), path) #save the neural network state\n",
    "        print('Model saved at', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancer l'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1):\n",
    "    eval_sacc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1):\n",
    "    eval_sacc(fig_type='log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
