% $ biblatex auxiliary file $
% $ biblatex bbl format version 2.9 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated as
% required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup

\datalist[entry]{nty/global//global/global}
  \entry{Freeman2011}{article}{}
    \name{author}{2}{}{%
      {{hash=FJ}{%
         family={Freeman},
         familyi={F\bibinitperiod},
         given={Jeremy},
         giveni={J\bibinitperiod},
      }}%
      {{hash=SEP}{%
         family={Simoncelli},
         familyi={S\bibinitperiod},
         given={Eero\bibnamedelima P.},
         giveni={E\bibinitperiod\bibinitdelim P\bibinitperiod},
      }}%
    }
    \strng{namehash}{FJSEP1}
    \strng{fullhash}{FJSEP1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{F}
    \field{sortinithash}{F}
    \field{abstract}{%
    The human capacity to recognize complex visual patterns emerges in a
  sequence of brain areas known as the ventral stream, beginning with primary
  visual cortex (V1). We developed a population model for mid-ventral
  processing, in which nonlinear combinations of V1 responses are averaged in
  receptive fields that grow with eccentricity. To test the model, we generated
  novel forms of visual metamers, stimuli that differ physically but look the
  same. We developed a behavioral protocol that uses metameric stimuli to
  estimate the receptive field sizes in which the model features are
  represented. Because receptive field sizes change along the ventral stream,
  our behavioral results can identify the visual area corresponding to the
  representation. Measurements in human observers implicate visual area V2,
  providing a new functional account of neurons in this area. The model also
  explains deficits of peripheral vision known as crowding, and provides a
  quantitative framework for assessing the capabilities and limitations of
  everyday vision.%
    }
    \verb{doi}
    \verb 10.1038/nn.2889
    \endverb
    \field{isbn}{1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)}
    \field{issn}{10976256}
    \field{number}{9}
    \field{pages}{1195\bibrangedash 1204}
    \field{title}{{Metamers of the ventral stream}}
    \field{volume}{14}
    \verb{file}
    \verb :home/albert/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloa
    \verb ded/Freeman, Simoncelli - 2011 - Metamers of the ventral stream.pdf:p
    \verb df
    \endverb
    \field{journaltitle}{Nature Neuroscience}
    \field{year}{2011}
  \endentry

  \entry{Kortum1996}{article}{}
    \name{author}{2}{}{%
      {{hash=KP}{%
         family={Kortum},
         familyi={K\bibinitperiod},
         given={Philip},
         giveni={P\bibinitperiod},
      }}%
      {{hash=GWS}{%
         family={Geisler},
         familyi={G\bibinitperiod},
         given={Wilson\bibnamedelima S.},
         giveni={W\bibinitperiod\bibinitdelim S\bibinitperiod},
      }}%
    }
    \keyw{area-of-interest,eye,field-of-view,foveation,gaze contingent,image
  compression,movements}
    \strng{namehash}{KPGWS1}
    \strng{fullhash}{KPGWS1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{K}
    \field{sortinithash}{K}
    \field{abstract}{%
    We have developed a preliminary version of a foveated imaging system,
  implemented on a general purpose computer, which greatly reduces the
  transmission bandwidth of images. The system is based on the fact that the
  spatial resolution of the human eye is space variant, decreasing with
  increasing eccentricity from the point of gaze. By taking advantage of this
  fact, it is possible to create an image that is almost perceptually
  indistinguishable from a constant resolution image, but requires
  substantially less information to code it. This is accomplished by degrading
  the resolution of the image so that it matches the space-variant degradation
  in the resolution of the human eye. Eye movements are recorded so that the
  high resolution region of the image can be kept aligned with the high
  resolution region of the human visual system. This system has demonstrated
  that significant reductions in bandwidth can be achieved while still
  maintaining access to high detail at any point in an image. The system has
  been tested using 256x256 8 bit gray scale images with 20Â° fields-of-view
  and eye-movement update rates of 30 Hz (display refresh was 60 Hz). Users of
  the system have reported minimal perceptual artifacts at bandwidth reductions
  of up to 94.7{\%} (18.8 times reduction)%
    }
    \verb{doi}
    \verb 10.1117/12.238732
    \endverb
    \field{isbn}{081942031X}
    \field{issn}{0277786X}
    \field{pages}{350\bibrangedash 360}
    \field{title}{{Implementation of a foveated image coding system for image
  bandwidth reduction}}
    \field{volume}{2657}
    \verb{file}
    \verb :home/albert/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloa
    \verb ded/Kortum, Geisler - 1996 - Implementation of a foveated image codin
    \verb g system for image bandwidth reduction.pdf:pdf
    \endverb
    \field{journaltitle}{SPIE Proceedings}
    \field{year}{1996}
  \endentry

  \entry{Krauzlis2017}{article}{}
    \name{author}{3}{}{%
      {{hash=KRJ}{%
         family={Krauzlis},
         familyi={K\bibinitperiod},
         given={Richard\bibnamedelima J.},
         giveni={R\bibinitperiod\bibinitdelim J\bibinitperiod},
      }}%
      {{hash=GL}{%
         family={Goffart},
         familyi={G\bibinitperiod},
         given={Laurent},
         giveni={L\bibinitperiod},
      }}%
      {{hash=HZM}{%
         family={Hafed},
         familyi={H\bibinitperiod},
         given={Ziad\bibnamedelima M.},
         giveni={Z\bibinitperiod\bibinitdelim M\bibinitperiod},
      }}%
    }
    \keyw{behaviour,neuroscience}
    \strng{namehash}{KRJGLHZM1}
    \strng{fullhash}{KRJGLHZM1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{K}
    \field{sortinithash}{K}
    \field{abstract}{%
    Ocular fixation is a dynamic process that is actively controlled by many of
  the same brain structures involved in the control of eye movements, including
  the superior colliculus, cerebellum and reticular formation. In this article,
  we review several aspects of this active control. First, the decision to move
  the eyes not only depends on target-related signals from the peripheral
  visual field, but also on signals from the currently fixated target at the
  fovea, and involves mechanisms that are shared between saccades and smooth
  pursuit. Second, eye position during fixation is actively controlled and
  depends on bilateral activity in the superior colliculi and medio-posterior
  cerebellum; disruption of activity in these circuits causes systematic
  deviations in eye position during both fixation and smooth pursuit eye
  movements. Third, the eyes are not completely still during fixation but make
  continuous miniature movements, including ocular drift and microsaccades,
  which are controlled by the same neuronal mechanisms that generate larger
  saccades. Finally, fixational eye movements have large effects on visual
  perception. Ocular drift transforms the visual input in ways that increase
  spatial acuity; microsaccades not only improve vision by relocating the fovea
  but also cause momentary changes in vision analogous to those caused by
  larger saccades.This article is part of the themed issue 'Movement
  suppression: brain mechanisms for stopping and stillness'.%
    }
    \verb{doi}
    \verb 10.1098/rstb.2016.0205
    \endverb
    \field{isbn}{0000000187671}
    \field{issn}{0962-8436}
    \field{number}{1718}
    \field{pages}{20160205}
    \field{title}{{Neuronal control of fixation and fixational eye movements}}
    \verb{url}
    \verb http://rstb.royalsocietypublishing.org/lookup/doi/10.1098/rstb.2016.0
    \verb 205
    \endverb
    \field{volume}{372}
    \verb{file}
    \verb :home/albert/Documents/ActiveVision/Articles/Krauzlis2017.pdf:pdf
    \endverb
    \field{journaltitle}{Philosophical Transactions of the Royal Society B:
  Biological Sciences}
    \field{year}{2017}
  \endentry

  \entry{Leon2012}{article}{}
    \name{author}{4}{}{%
      {{hash=LPS}{%
         family={Leon},
         familyi={L\bibinitperiod},
         given={P.\bibnamedelima S.},
         giveni={P\bibinitperiod\bibinitdelim S\bibinitperiod},
      }}%
      {{hash=VI}{%
         family={Vanzetta},
         familyi={V\bibinitperiod},
         given={I.},
         giveni={I\bibinitperiod},
      }}%
      {{hash=MGS}{%
         family={Masson},
         familyi={M\bibinitperiod},
         given={G.\bibnamedelima S.},
         giveni={G\bibinitperiod\bibinitdelim S\bibinitperiod},
      }}%
      {{hash=PLU}{%
         family={Perrinet},
         familyi={P\bibinitperiod},
         given={L.\bibnamedelima U.},
         giveni={L\bibinitperiod\bibinitdelim U\bibinitperiod},
      }}%
    }
    \strng{namehash}{LPS+1}
    \strng{fullhash}{LPSVIMGSPLU1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{L}
    \field{sortinithash}{L}
    \field{abstract}{%
    Choosing an appropriate set of stimuli is essential to characterize the
  response of a sensory system to a particular functional dimension, such as
  the eye movement following the motion of a visual scene. Here, we describe a
  framework to generate random texture movies with controlled information
  content, i.e., Motion Clouds. These stimuli are defined using a generative
  model that is based on controlled experimental parametrization. We show that
  Motion Clouds correspond to dense mixing of localized moving gratings with
  random positions. Their global envelope is similar to natural-like
  stimulation with an approximate full-field translation corresponding to a
  retinal slip. We describe the construction of these stimuli mathematically
  and propose an open-source Python-based implementation. Examples of the use
  of this framework are shown. We also propose extensions to other modalities
  such as color vision, touch, and audition.%
    }
    \verb{doi}
    \verb 10.1152/jn.00737.2011
    \endverb
    \verb{eprint}
    \verb arXiv:1208.6467v1
    \endverb
    \field{isbn}{1522-1598 (Electronic)$\backslash$n0022-3077 (Linking)}
    \field{issn}{0022-3077}
    \field{number}{11}
    \field{pages}{3217\bibrangedash 3226}
    \field{title}{{Motion clouds: model-based stimulus synthesis of
  natural-like random textures for the study of motion perception}}
    \verb{url}
    \verb http://jn.physiology.org/cgi/doi/10.1152/jn.00737.2011
    \endverb
    \field{volume}{107}
    \verb{file}
    \verb :home/albert/Downloads/Leon2012:
    \endverb
    \field{journaltitle}{Journal of Neurophysiology}
    \field{eprinttype}{arXiv}
    \field{year}{2012}
  \endentry

  \entry{Perlin1985}{article}{}
    \name{author}{1}{}{%
      {{hash=PK}{%
         family={Perlin},
         familyi={P\bibinitperiod},
         given={Ken},
         giveni={K\bibinitperiod},
      }}%
    }
    \keyw{Algorithm,Stochastic process,Texture mapping}
    \strng{namehash}{PK1}
    \strng{fullhash}{PK1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{P}
    \field{sortinithash}{P}
    \field{abstract}{%
    We introduce the concept of a Pixel Stream Editor. This forms the basis for
  an interactive synthesizer for designing highly realistic Computer Generated
  Imagery. The designer works in an interactive Very High Level programming
  environment which provides a very fast concept/implement/view iteration
  cycle.Naturalistic visual complexity is built up by composition of non-linear
  functions, as opposed to the more conventional texture mapping or growth
  model algorithms. Powerful primitives are included for creating controlled
  stochastic effects. We introduce the concept of "solid texture" to the field
  of CGI.We have used this system to create very convincing representations of
  clouds, fire, water, stars, marble, wood, rock, soap films and crystal. The
  algorithms created with this paradigm are generally extremely fast, highly
  realistic, and asynchronously parallelizable at the pixel level.%
    }
    \verb{doi}
    \verb 10.1145/325334.325247
    \endverb
    \field{number}{3}
    \field{pages}{287\bibrangedash 296}
    \field{title}{{An image synthesizer}}
    \field{volume}{19}
    \field{journaltitle}{Computer Graphics}
    \field{year}{1985}
  \endentry

  \entry{Werner2014}{book}{}
    \name{editor}{2}{}{%
      {{hash=WJS}{%
         family={Werner},
         familyi={W\bibinitperiod},
         given={John\bibnamedelima S.},
         giveni={J\bibinitperiod\bibinitdelim S\bibinitperiod},
      }}%
      {{hash=CLM}{%
         family={Chalupa},
         familyi={C\bibinitperiod},
         given={Leo\bibnamedelima M.},
         giveni={L\bibinitperiod\bibinitdelim M\bibinitperiod},
      }}%
    }
    \keyw{Neuroscience,Vision,Visual cortex,Visual pathways}
    \strng{namehash}{WJSCLM1}
    \strng{fullhash}{WJSCLM1}
    \field{labelnamesource}{editor}
    \field{labeltitlesource}{title}
    \field{sortinit}{W}
    \field{sortinithash}{W}
    \field{edition}{MIT Press}
    \field{isbn}{9780262019163}
    \field{pages}{1675}
    \field{title}{{The new visual neurosciences}}
    \field{year}{2014}
  \endentry

  \entry{Zhaoping2014}{book}{}
    \name{author}{1}{}{%
      {{hash=ZL}{%
         family={Zhaoping},
         familyi={Z\bibinitperiod},
         given={Li},
         giveni={L\bibinitperiod},
      }}%
    }
    \keyw{Mathematics,Neuroscience,Vison}
    \strng{namehash}{ZL1}
    \strng{fullhash}{ZL1}
    \field{labelnamesource}{author}
    \field{labeltitlesource}{title}
    \field{sortinit}{Z}
    \field{sortinithash}{Z}
    \field{edition}{Oxford Uni}
    \field{isbn}{9780199564668}
    \field{pages}{383}
    \field{title}{{Understanding vision : theory, models and data}}
    \field{year}{2014}
  \endentry
\enddatalist
\endinput
