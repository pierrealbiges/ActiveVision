{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-02-05 - Rapport\n",
    "---\n",
    "Avancées notées dans la partie To-Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-02-06 - Rapport\n",
    "---\n",
    "Avancées notées dans la partie To-Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-02-07 - Rapport, Classifieur\n",
    "---\n",
    "Aujourd'hui a été réglé un problème trainant depuis quelques jours. La ligne :\n",
    "\n",
    "    saver.restore(sess, \"/home/pimt/Documents/Notebooks/TF_graph_logpolar.ckpt\")\n",
    "\n",
    "ne semblait pas fontionner correctement, et ne restaurait pas les valeurs tirées de l'entraînement, enregistrées via TensorFlow.  \n",
    "Les valeurs des poids étaient réinitialisées (en l'occurance le produit d'un random normé) comme si l'apprentissage n'avait pas eu lieu.   \n",
    "Le problème semble réglé en modifiant la ligne : \n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "en :\n",
    "\n",
    "    saver = tf.train.Saver(var_list={\"weights_detect\": weights_detect, \"weights_classif\": weights_classif})\n",
    "\n",
    "La solution est contre-intuitive sachant que dans sa première version, la commande doit enregistrer l'ensemble du graph (y compris donc les poids), et que ceux-ci étaient déja nommés via l'argument \"name\" (donc l'erreur ne pouvait pas provenir d'une absence de correspondance nom-variable) : \n",
    "\n",
    "    weights_detect = tf.Variable(tf.random_normal([480,2], stddev=0.01), name='weights_detect')    # poids (coordonnées)\n",
    "\n",
    "    weights_classif = tf.Variable(tf.random_normal([480,10], stddev=0.01), name='weights_classif') # poids (classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-02-08 - Classifieur\n",
    "---\n",
    "Après avoir remarqué des performances très faibles du classifieur, je suis allé jeter un oeil du côté des poids durant l'apprentissage : ceux-ci n'évoluent presque pas.  \n",
    "J'ai donc voulu construire des graphiques à partir du coût, pour vérifier qu'ils ne bougaient pas simplement parce qu'ils étaient très vite optimisés.  \n",
    "Le coût ne bougent presque pas non plus au fil de l'entraînement.  \n",
    "\n",
    "De plus, la [documentation](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits) conseille de remplacer :  \n",
    "\n",
    "    cost_classif = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=classif)\n",
    "    \n",
    "par : \n",
    "\n",
    "    cost_classif = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=classif)\n",
    "    \n",
    "Mais cette dernière me renvoie une erreur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018-02-09 - Classifieur\n",
    "---\n",
    "Pour montrer que les poids ne bougent presque pas lors de l'entrainement :\n",
    "\n",
    "    batch_size = 300\n",
    "    iterations = 20\n",
    "    alpha = 3 # valeur abérante pour forcer un apprentissage, qui à surapprendre\n",
    "    \n",
    "    cost_classif_value = sess.run(cost_classif, {x_train: values, labels: labels_values})\n",
    "    cost_classif_graph += [np.mean(cost_classif_value)]\n",
    "    print(cost_classif_graph)\n",
    "    \n",
    "    > [2.2295258, 2.2820525, 2.337817, 2.3211503, 2.307812, 2.3244836, 2.3178129, 2.3110623, 2.3344829, 2.2711504, 2.2878113, 2.2977173, 2.3276615, 2.3044837, 2.2909455, 2.2977993, 2.3044622, 2.3044837, 2.3111479, 2.3076708]\n",
    "    \n",
    "Les coûts sont très bas dès le début de l'entraînement, est-ce que ça signifie que même optimisé, le classifieur est peu performant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# To Do\n",
    "+ ~~Partager le groupe Mendely avec Daucé et Perrinet~~\n",
    "+ S'inscrire sur la liste de diffusion de l'INS\n",
    "+ Traduire le rapport en anglais?\n",
    "### Waveimage_TensorFlow\n",
    "+ Créer un classifier pour stopper les saccades lorsque la cible est identifiée\n",
    "    + ~~Introduire les saccades~~\n",
    "    + ~~Introduire la prédiction de la classe de la cible par le classifier~~\n",
    "    + **Améliorer la méthode d'apprentissage du classifieur (performances très faibles)**\n",
    "+ Créer une ou plusieurs méthodes pour introduire du bruit écologique dans les images\n",
    "+ Traduire en modèle probabiliste\n",
    "+ ~~Résoudre le problème de chargement du graph~~\n",
    "+ ~~Résoudre le problème de valeurs nulles augmentant exponentiellement de weights_detect~~ -> Réglé seulement temporairement ?\n",
    "+ **Introduire le whitening de l'image dans l'apprentissage**\n",
    "+ Créer graphique \"nb essais/nb saccades pr atteindre cible\"\n",
    "+ Créer graphique \"nb moyen saccades/distance initiale à fovéa\"\n",
    "+ Se renseigner sur cet [optimiseur](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer) pour améliorer l'apprentissage du détecteur\n",
    "### Waveimage-tensorflow-pow3-encoding_P3ver\n",
    "+ Créer un graphique : nombre de saccades nécessaires à atteindre la cible en fonction de sa distance du point de fixation\n",
    "+ Créer un classifier pour stopper les saccades lorsque la cible est identifiée\n",
    "    + Entrainer le classifier\n",
    "    + Evaluer les performances du classifier\n",
    "+ Traduire le modèle en modèle probabiliste\n",
    "+ Créer une ou plusieurs méthodes pour introduire du bruit dans les images\n",
    "+ Réaliser une transformation coordonnées -> degrés et adapter le modèle pour les utiliser\n",
    "### mnist-logPolar-encoding\n",
    "+ Ecrire un script réalisant un apprentissage par régression linéaire en utilisant les sorties de la partie \"Energy\"\n",
    "+ Intégrer un bruit écologique aux images (cf Najemnik2005 (chercher la méthode utilisée dans les sources); librairie [SLIP](https://nbviewer.jupyter.org/github/bicv/SLIP/blob/master/SLIP.ipynb) de Laurent)\n",
    "### Rapport M2a\n",
    "+ ~~Ecrire une ébauche d'introduction~~\n",
    "+ Créer les fichers pour les autres chapitres\n",
    "    + Résultats\n",
    "    + Discussion\n",
    "    + ~~Annexes~~\n",
    "+ ~~Ecrire une ébauche de matériel~~\n",
    "+ **Ecrire une ébauche de méthodes**\n",
    "+ ~~Changer le style de bibliographie~~\n",
    "+ Changer le style de *sorting* des citations (= citer dans l'ordre)\n",
    "+ Intégrer toutes les sources au texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# A lire\n",
    "+ http://bethgelab.org/media/publications/Kuemmerer_High_Low_Level_Fixations_ICCV_2017.pdf\n",
    "+ https://pdfs.semanticscholar.org/0182/5573781674bcf85d0f5d2ec456842f75ad3c.pdf\n",
    "+ Schmidhuber, 1991 (voir mail Daucé)\n",
    "+ Parr and Friston, 2017 (voir mail Perrinet)\n",
    "+ http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003005#s1\n",
    "+ http://rpg.ifi.uzh.ch/docs/RAL18_Loquercio.pdf\n",
    "+ https://www.nature.com/articles/sdata2016126\n",
    "+ [Liu et al., 2016](http://ieeexplore.ieee.org/document/7762165/?reload=true) : Learning to Predict Eye Fixations via Multiresolution Convolutional Neural Networks\n",
    "### Magnocellular pathway function  \n",
    "+ [Selective suppression of the magnocellular visual pathway during saccadic eye movements](http://www.nature.com.lama.univ-amu.fr/articles/371511a0), Burr1994\n",
    "+ [On Identifying Magnocellular and Parvocellular Responses on the Basis of Contrast-Response Functions](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3004196/), Skottun2011\n",
    "+ [Review: Steady and pulsed pedestals, the how and why of post-receptoral pathway separation](http://jov.arvojournals.org/article.aspx?articleid=2191890), Pokorny2011\n",
    "+ [An evolving view of duplex vision: separate but interacting cortical pathways for perception and action](http://www.sciencedirect.com/science/article/pii/S0959438804000340?via%3Dihub), Goodale2004\n",
    "+ [Quantitative measurement of saccade amplitude, duration, and velocity](http://n.neurology.org/content/25/11/1065), Baloh1975"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Satellites"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
