% $ biblatex auxiliary file $
% $ biblatex version 2.6 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated as
% required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup

\entry{Butko2010}{article}{}
  \name{author}{2}{}{%
    {{}%
     {Butko}{B.}%
     {Nicholas~J}{N.~J.}%
     {}{}%
     {}{}}%
    {{}%
     {Movellan}{M.}%
     {Javier~R}{J.~R.}%
     {}{}%
     {}{}}%
  }
  \strng{namehash}{BNJMJR1}
  \strng{fullhash}{BNJMJR1}
  \field{sortinit}{B}
  \field{number}{2}
  \field{pages}{91\bibrangedash 107}
  \field{title}{{Infomax control of eye movements}}
  \field{volume}{2}
  \verb{file}
  \verb :home/pimt/Documents/Articles/Butko2010.pdf:pdf
  \endverb
  \field{journaltitle}{Autonomous Mental Development, IEEE Transactions on}
  \field{year}{2010}
\endentry

\entry{Denison2014}{article}{}
  \name{author}{5}{}{%
    {{}%
     {Denison}{D.}%
     {Rachel~N.}{R.~N.}%
     {}{}%
     {}{}}%
    {{}%
     {Vu}{V.}%
     {An~T.}{A.~T.}%
     {}{}%
     {}{}}%
    {{}%
     {Yacoub}{Y.}%
     {Essa}{E.}%
     {}{}%
     {}{}}%
    {{}%
     {Feinberg}{F.}%
     {David~A.}{D.~A.}%
     {}{}%
     {}{}}%
    {{}%
     {Silver}{S.}%
     {Michael~A.}{M.~A.}%
     {}{}%
     {}{}}%
  }
  \keyw{7T,FMRI,Lateral geniculate nucleus,Magnocellular,Parallel
  processing,Parvocellular}
  \strng{namehash}{DRN+1}
  \strng{fullhash}{DRNVATYEFDASMA1}
  \field{sortinit}{D}
  \field{abstract}{%
  The magnocellular (M) and parvocellular (P) subdivisions of primate LGN are
  known to process complementary types of visual stimulus information, but a
  method for noninvasively defining these subdivisions in humans has proven
  elusive. As a result, the functional roles of these subdivisions in humans
  have not been investigated physiologically. To functionally map the M and P
  subdivisions of human LGN, we used high-resolution fMRI at high field (7. T
  and 3. T) together with a combination of spatial, temporal, luminance, and
  chromatic stimulus manipulations. We found that stimulus factors that
  differentially drive magnocellular and parvocellular neurons in primate LGN
  also elicit differential BOLD fMRI responses in human LGN and that these
  responses exhibit a spatial organization consistent with the known anatomical
  organization of the M and P subdivisions. In test-retest studies, the
  relative responses of individual voxels to M-type and P-type stimuli were
  reliable across scanning sessions on separate days and across sessions at
  different field strengths. The ability to functionally identify magnocellular
  and parvocellular regions of human LGN with fMRI opens possibilities for
  investigating the functions of these subdivisions in human visual perception,
  in patient populations with suspected abnormalities in one of these
  subdivisions, and in visual cortical processing streams arising from parallel
  thalamocortical pathways. {\textcopyright} 2014 Elsevier Inc.%
  }
  \verb{doi}
  \verb 10.1016/j.neuroimage.2014.07.019
  \endverb
  \verb{eprint}
  \verb 15334406
  \endverb
  \field{isbn}{1095-9572 (Electronic) 1053-8119 (Linking)}
  \field{issn}{10959572}
  \field{number}{P2}
  \field{pages}{358\bibrangedash 369}
  \field{title}{{Functional mapping of the magnocellular and parvocellular
  subdivisions of human LGN}}
  \field{volume}{102}
  \verb{file}
  \verb :home/pimt/Documents/Articles/Denison2014.pdf:pdf
  \endverb
  \field{journaltitle}{NeuroImage}
  \field{eprinttype}{arXiv}
  \field{year}{2014}
\endentry

\entry{Fischer2007}{article}{}
  \name{author}{4}{}{%
    {{}%
     {Fischer}{F.}%
     {Sylvain}{S.}%
     {}{}%
     {}{}}%
    {{}%
     {Perrinet}{P.}%
     {Laurent}{L.}%
     {}{}%
     {}{}}%
    {{}%
     {Redondo}{R.}%
     {Rafael}{R.}%
     {}{}%
     {}{}}%
    {{}%
     {Cristobal}{C.}%
     {Gabriel}{G.}%
     {}{}%
     {}{}}%
  }
  \keyw{ARTIFICIAL INTELLIGENCE,Artificial Intelligence (incl.
  Robotics),COMPRESSION,COMPUTER SCIENCE,CORTICAL-CELLS,Computer
  Imaging,Computer Science,FILTERS,IMAGE REPRESENTATION,Image Processing and
  Computer Vision,NATURAL IMAGES,Pattern Recognition,Pattern Recognition and
  Graphics,RESPONSES,SPATIAL-FREQUENCY,STATISTICS,Studies,TRANSFORMS,VISUAL-CORTEX,Vision,Wavelet
  transforms,image denoising,log-Gabor filters,oriented high-pass
  filters,visual system,wavelet transforms}
  \strng{namehash}{FS+1}
  \strng{fullhash}{FSPLRRCG1}
  \field{sortinit}{F}
  \verb{doi}
  \verb 10.1007/s11263-006-0026-8
  \endverb
  \field{number}{2}
  \field{pages}{231\bibrangedash 246}
  \field{title}{{Self-invertible 2D log-Gabor wavelets}}
  \verb{url}
  \verb http://invibe.net/LaurentPerrinet/Publications/Fischer07cv?action=Attac
  \verb hFile{\&}do=view{\&}target=Fischer07cv.pdf
  \endverb
  \field{volume}{75}
  \verb{file}
  \verb :home/pimt/Documents/Articles/Fischer2007.pdf:pdf
  \endverb
  \field{journaltitle}{International Journal of Computer Vision}
  \field{year}{2007}
\endentry

\entry{Freeman2011}{article}{}
  \name{author}{2}{}{%
    {{}%
     {Freeman}{F.}%
     {Jeremy}{J.}%
     {}{}%
     {}{}}%
    {{}%
     {Simoncelli}{S.}%
     {Eero~P.}{E.~P.}%
     {}{}%
     {}{}}%
  }
  \strng{namehash}{FJSEP1}
  \strng{fullhash}{FJSEP1}
  \field{sortinit}{F}
  \field{abstract}{%
  The human capacity to recognize complex visual patterns emerges in a sequence
  of brain areas known as the ventral stream, beginning with primary visual
  cortex (V1). We developed a population model for mid-ventral processing, in
  which nonlinear combinations of V1 responses are averaged in receptive fields
  that grow with eccentricity. To test the model, we generated novel forms of
  visual metamers, stimuli that differ physically but look the same. We
  developed a behavioral protocol that uses metameric stimuli to estimate the
  receptive field sizes in which the model features are represented. Because
  receptive field sizes change along the ventral stream, our behavioral results
  can identify the visual area corresponding to the representation.
  Measurements in human observers implicate visual area V2, providing a new
  functional account of neurons in this area. The model also explains deficits
  of peripheral vision known as crowding, and provides a quantitative framework
  for assessing the capabilities and limitations of everyday vision.%
  }
  \verb{doi}
  \verb 10.1038/nn.2889
  \endverb
  \field{isbn}{1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)}
  \field{issn}{10976256}
  \field{number}{9}
  \field{pages}{1195\bibrangedash 1204}
  \field{title}{{Metamers of the ventral stream}}
  \field{volume}{14}
  \verb{file}
  \verb :home/pimt/Documents/Articles/Freeman2011.pdf:pdf
  \endverb
  \field{journaltitle}{Nature Neuroscience}
  \field{year}{2011}
\endentry

\entry{Friston2012}{article}{}
  \name{author}{4}{}{%
    {{}%
     {Friston}{F.}%
     {Karl}{K.}%
     {}{}%
     {}{}}%
    {{}%
     {Adams}{A.}%
     {Rick~A.}{R.~A.}%
     {}{}%
     {}{}}%
    {{}%
     {Perrinet}{P.}%
     {Laurent}{L.}%
     {}{}%
     {}{}}%
    {{}%
     {Breakspear}{B.}%
     {Michael}{M.}%
     {}{}%
     {}{}}%
  }
  \keyw{Active inference,Bayesian inference,Exploration,Free
  energy,Perception,Salience,Surprise,Visual search}
  \strng{namehash}{FK+1}
  \strng{fullhash}{FKARAPLBM1}
  \field{sortinit}{F}
  \field{abstract}{%
  If perception corresponds to hypothesis testing (Gregory, 1980); then visual
  searches might be construed as experiments that generate sensory data. In
  this work, we explore the idea that saccadic eye movements are optimal
  experiments, in which data are gathered to test hypotheses or beliefs about
  how those data are caused. This provides a plausible model of visual search
  that can be motivated from the basic principles of self-organized behavior:
  namely, the imperative to minimize the entropy of hidden states of the world
  and their sensory consequences. This imperative is met if agents sample
  hidden states of the world efficiently. This efficient sampling of salient
  information can be derived in a fairly straightforward way, using approximate
  Bayesian inference and variational free-energy minimization. Simulations of
  the resulting active inference scheme reproduce sequential eye movements that
  are reminiscent of empirically observed saccades and provide some
  counterintuitive insights into the way that sensory evidence is accumulated
  or assimilated into beliefs about the world.%
  }
  \verb{doi}
  \verb 10.3389/fpsyg.2012.00151
  \endverb
  \verb{eprint}
  \verb NIHMS150003
  \endverb
  \field{isbn}{1664-1078 (Electronic)}
  \field{issn}{16641078}
  \field{number}{MAY}
  \field{pages}{1\bibrangedash 20}
  \field{title}{{Perceptions as hypotheses: Saccades as experiments}}
  \field{volume}{3}
  \verb{file}
  \verb :home/pimt/Documents/Articles/Friston2012.pdf:pdf
  \endverb
  \field{journaltitle}{Frontiers in Psychology}
  \field{eprinttype}{arXiv}
  \field{year}{2012}
\endentry

\entry{Goodale2004}{article}{}
  \name{author}{2}{}{%
    {{}%
     {Goodale}{G.}%
     {Melvyn~A.}{M.~A.}%
     {}{}%
     {}{}}%
    {{}%
     {Westwood}{W.}%
     {David~A.}{D.~A.}%
     {}{}%
     {}{}}%
  }
  \keyw{AIP,Anterior intraparietal sulcus,Area LO,Functional magnetic resonance
  imaging,LOC,Lateral occipital area,Lateral occipital complex,MRI,Magnetic
  resonance imaging,RF,Rod-and-frame,ST,Simultaneous tilt,TMS,Transcranial
  magnetic stimulation,fMRI}
  \strng{namehash}{GMAWDA1}
  \strng{fullhash}{GMAWDA1}
  \field{sortinit}{G}
  \field{abstract}{%
  In 1992, Goodale and Milner proposed a division of labour in the visual
  pathways of the primate cerebral cortex between a dorsal stream specialised
  for the visual control of action and a ventral stream dedicated to the
  perception of the visual world. In the years since this original proposal,
  support for the perception-action hypothesis has come from neuroimaging
  experiments, human neuropsychology, monkey neurophysiology, and human
  psychophysical experiments. Indeed, some of the strongest support for this
  hypothesis has come from behavioural experiments showing that visually guided
  actions are largely refractory to perceptual illusions. Although
  controversial, the findings from this literature both support the original
  hypothesis and suggest important modifications. The ongoing challenge for
  neurobiologists is to map these behavioural findings onto their corresponding
  neural substrates.%
  }
  \verb{doi}
  \verb 10.1016/j.conb.2004.03.002
  \endverb
  \field{isbn}{0959-4388 (Print)$\backslash$r0959-4388 (Linking)}
  \field{issn}{09594388}
  \field{number}{2}
  \field{pages}{203\bibrangedash 211}
  \field{title}{{An evolving view of duplex vision: Separate but interacting
  cortical pathways for perception and action}}
  \field{volume}{14}
  \verb{file}
  \verb :home/pimt/Documents/Articles/Goodale2004.pdf:pdf
  \endverb
  \field{journaltitle}{Current Opinion in Neurobiology}
  \field{year}{2004}
\endentry

\entry{Itti2000}{article}{}
  \name{author}{2}{}{%
    {{}%
     {Itti}{I.}%
     {Laurent}{L.}%
     {}{}%
     {}{}}%
    {{}%
     {Koch}{K.}%
     {Christof}{C.}%
     {}{}%
     {}{}}%
  }
  \keyw{saliency,vision systems,visual attention}
  \strng{namehash}{ILKC1}
  \strng{fullhash}{ILKC1}
  \field{sortinit}{I}
  \field{abstract}{%
  Most models of visual search, whether involving overt eye movements or covert
  shifts of attention, are based on the concept of a saliency map, that is, an
  explicit two-dimensional map that encodes the saliency or conspicuity of
  objects in the visual environment. Competition among neurons in this map
  gives rise to a single winning location that corresponds to the next attended
  target. Inhibiting this location automatically allows the system to attend to
  the next most salient location. We describe a detailed computer
  implementation of such a scheme, focusing on the problem of combining
  information across modalities, here orientation, intensity and color
  information, in a purely stimulus-driven manner. The model is applied to
  common psychophysical stimuli as well as to a very demanding visual search
  task. Its successful performance is used to address the extent to which the
  primate visual system carries out visual search via one or more such saliency
  maps and how this can be tested.%
  }
  \verb{doi}
  \verb 10.1016/S0042-6989(99)00163-7
  \endverb
  \field{issn}{0042-6989}
  \field{number}{10-12}
  \field{pages}{1489\bibrangedash 1506}
  \field{title}{{A saliency-based search mechanism for overt and covert hifts
  of visual attention}}
  \field{volume}{40}
  \verb{file}
  \verb :home/pimt/Documents/Articles/Itti1999.pdf:pdf
  \endverb
  \field{journaltitle}{Vision Research}
  \field{year}{2000}
\endentry

\entry{Kortum1996}{article}{}
  \name{author}{2}{}{%
    {{}%
     {Kortum}{K.}%
     {Philip}{P.}%
     {}{}%
     {}{}}%
    {{}%
     {Geisler}{G.}%
     {Wilson~S.}{W.~S.}%
     {}{}%
     {}{}}%
  }
  \keyw{area-of-interest,eye,field-of-view,foveation,gaze contingent,image
  compression,movements}
  \strng{namehash}{KPGWS1}
  \strng{fullhash}{KPGWS1}
  \field{sortinit}{K}
  \field{abstract}{%
  We have developed a preliminary version of a foveated imaging system,
  implemented on a general purpose computer, which greatly reduces the
  transmission bandwidth of images. The system is based on the fact that the
  spatial resolution of the human eye is space variant, decreasing with
  increasing eccentricity from the point of gaze. By taking advantage of this
  fact, it is possible to create an image that is almost perceptually
  indistinguishable from a constant resolution image, but requires
  substantially less information to code it. This is accomplished by degrading
  the resolution of the image so that it matches the space-variant degradation
  in the resolution of the human eye. Eye movements are recorded so that the
  high resolution region of the image can be kept aligned with the high
  resolution region of the human visual system. This system has demonstrated
  that significant reductions in bandwidth can be achieved while still
  maintaining access to high detail at any point in an image. The system has
  been tested using 256x256 8 bit gray scale images with 20° fields-of-view
  and eye-movement update rates of 30 Hz (display refresh was 60 Hz). Users of
  the system have reported minimal perceptual artifacts at bandwidth reductions
  of up to 94.7{\%} (18.8 times reduction)%
  }
  \verb{doi}
  \verb 10.1117/12.238732
  \endverb
  \field{isbn}{081942031X}
  \field{issn}{0277786X}
  \field{pages}{350\bibrangedash 360}
  \field{title}{{Implementation of a foveated image coding system for image
  bandwidth reduction}}
  \field{volume}{2657}
  \verb{file}
  \verb :home/pimt/Documents/Articles/Kortum1996.pdf:pdf
  \endverb
  \field{journaltitle}{SPIE Proceedings}
  \field{year}{1996}
\endentry

\entry{Najemnik2005}{article}{}
  \name{author}{2}{}{%
    {{}%
     {Najemnik}{N.}%
     {J}{J}%
     {}{}%
     {}{}}%
    {{}%
     {Geisler}{G.}%
     {Wilson~S.}{W.~S.}%
     {}{}%
     {}{}}%
  }
  \strng{namehash}{NJGWS1}
  \strng{fullhash}{NJGWS1}
  \field{sortinit}{N}
  \field{pages}{387\bibrangedash 391}
  \field{title}{{Optimal eye movement strategies in visual search}}
  \verb{url}
  \verb http://dx.doi.org/10.1038/nature03390
  \endverb
  \field{volume}{434}
  \verb{file}
  \verb :home/pimt/Documents/Articles/Najemnik2005.pdf:pdf
  \endverb
  \field{journaltitle}{Nature reviews. Neuroscience}
  \field{year}{2005}
\endentry

\entry{SLIP}{misc}{}
  \name{author}{1}{}{%
    {{}%
     {Perrinet}{P.}%
     {Laurent}{L.}%
     {}{}%
     {}{}}%
  }
  \keyw{Image
  processing,Neuroscience,fourier,perception,textures,vision,whitening}
  \strng{namehash}{PL1}
  \strng{fullhash}{PL1}
  \field{sortinit}{P}
  \field{abstract}{%
  The SLIP library (https://github.com/bicv/SLIP) defines a simple
  object-oriented class for gray-scale image processing. Use it to create a
  SLIP object with a dedicated image size (and optionnaly some other useful
  parameters) - which you can use to apply common image processing routines to
  your images.%
  }
  \field{title}{{SLIP : a Simple Library for Image Processing}}
  \verb{url}
  \verb https://github.com/bicv/SLIP
  \endverb
\endentry

\entry{Potthast2016}{article}{}
  \name{author}{4}{}{%
    {{}%
     {Potthast}{P.}%
     {Christian}{C.}%
     {}{}%
     {}{}}%
    {{}%
     {Breitenmoser}{B.}%
     {Andreas}{A.}%
     {}{}%
     {}{}}%
    {{}%
     {Sha}{S.}%
     {Fei}{F.}%
     {}{}%
     {}{}}%
    {{}%
     {Sukhatme}{S.}%
     {Gaurav~S.}{G.~S.}%
     {}{}%
     {}{}}%
  }
  \list{publisher}{1}{%
    {Elsevier B.V.}%
  }
  \keyw{Active perception,Feature selection,Information-theory,Multi-view
  object recognition,Object change detection,Viewpoint selection}
  \strng{namehash}{PC+1}
  \strng{fullhash}{PCBASFSGS1}
  \field{sortinit}{P}
  \field{abstract}{%
  Many robots are limited in their operating capabilities, both computational
  and energy-wise. A strong desire exists to keep computation cost and energy
  consumption to a minimum when executing tasks like object recognition with a
  mobile robot. Adaptive action selection is a paradigm, offering great
  flexibility in trading off the cost of acquiring information against making
  robust and reliable inference under uncertainty. In this paper, we study
  active multi-view object recognition and describe an information-theoretic
  framework that combines and unifies two common techniques: online feature
  selection for reducing computational costs and view planning for resolving
  ambiguities and occlusions. Our algorithm adaptively chooses between the two
  strategies of either selecting only the features that are most informative to
  the recognition, or moving to a new viewpoint that optimally reduces the
  expected uncertainty on the identity of the object. This two step process
  allows us to keep overall computation cost minimal but simultaneously
  increase recognition accuracy. Extensive empirical studies on a large RGB-D
  dataset, and with two different feature sets, have validated the
  effectiveness of the proposed framework. Our experiments show that dynamic
  feature selection alone reduces the computation time at runtime 2.5–6 times
  and, when combining it with viewpoint selection, we significantly increase
  the recognition accuracy on average by 8{\%}–18{\%} absolute compared to
  systems that do not use these two strategies. By establishing a link between
  active object recognition and change detection, we were further able to use
  our framework for the follow-up task of actively detecting object change.
  Furthermore, we have successfully demonstrated the framework's applicability
  to a low-powered quadcopter platform with limited operating time.%
  }
  \verb{doi}
  \verb 10.1016/j.robot.2016.06.013
  \endverb
  \field{issn}{09218890}
  \field{pages}{31\bibrangedash 47}
  \field{title}{{Active multi-view object recognition: A unifying view on
  online feature selection and view planning}}
  \verb{url}
  \verb http://dx.doi.org/10.1016/j.robot.2016.06.013
  \endverb
  \field{volume}{84}
  \verb{file}
  \verb :home/pimt/Documents/Articles/Potthast2016.pdf:pdf
  \endverb
  \field{journaltitle}{Robotics and Autonomous Systems}
  \field{year}{2016}
\endentry

\entry{Uddin2004}{article}{}
  \name{author}{3}{}{%
    {{}%
     {Uddin}{U.}%
     {M~K}{M.~K.}%
     {}{}%
     {}{}}%
    {{}%
     {Ninose}{N.}%
     {Y}{Y}%
     {}{}%
     {}{}}%
    {{}%
     {Nakamizo}{N.}%
     {S}{S}%
     {}{}%
     {}{}}%
  }
  \keyw{1993,accuracy of spatial localization,adam,and hoek,course and,in which
  they demonstrated,ketelaars,kingma,memory-guided saccade,reported on the
  time,spatial localization,that localization performance,two-process
  model,visually guided saccade}
  \strng{namehash}{UMKNYNS1}
  \strng{fullhash}{UMKNYNS1}
  \field{sortinit}{U}
  \verb{doi}
  \verb 10.2117/psysoc.2004.28
  \endverb
  \field{issn}{00332852}
  \field{pages}{28\bibrangedash 34}
  \field{title}{{Accuracy and precision of spatial localization with and
  without saccadic eye movements: A test of the two-process model}}
  \field{volume}{47}
  \verb{file}
  \verb :home/pimt/Documents/Articles/Uddin2004.pdf:pdf
  \endverb
  \field{journaltitle}{Psychologia}
  \field{year}{2004}
\endentry

\entry{Werner2014}{book}{}
  \name{editor}{2}{}{%
    {{}%
     {Werner}{W.}%
     {John~S.}{J.~S.}%
     {}{}%
     {}{}}%
    {{}%
     {Chalupa}{C.}%
     {Leo~M.}{L.~M.}%
     {}{}%
     {}{}}%
  }
  \keyw{Neuroscience,Vision,Visual cortex,Visual pathways}
  \strng{namehash}{WJSCLM1}
  \strng{fullhash}{WJSCLM1}
  \field{sortinit}{W}
  \field{edition}{MIT Press}
  \field{isbn}{9780262019163}
  \field{pages}{1675}
  \field{title}{{The new visual neurosciences}}
  \field{year}{2014}
\endentry

\entry{Zhaoping2014}{book}{}
  \name{author}{1}{}{%
    {{}%
     {Zhaoping}{Z.}%
     {Li}{L.}%
     {}{}%
     {}{}}%
  }
  \keyw{Mathematics,Neuroscience,Vison}
  \strng{namehash}{ZL1}
  \strng{fullhash}{ZL1}
  \field{sortinit}{Z}
  \field{edition}{Oxford Uni}
  \field{isbn}{9780199564668}
  \field{pages}{383}
  \field{title}{{Understanding vision : theory, models and data}}
  \field{year}{2014}
\endentry

\lossort
\endlossort

\endinput
